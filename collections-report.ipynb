{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "import configparser \n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "ip = config['DEFAULT']['IP']\n",
    "port = config['DEFAULT']['MongoDB-Port']\n",
    "\n",
    "from pymongo import MongoClient\n",
    "client = MongoClient(ip, int(port))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(client.database_names())\n",
    "db_twitter = client[\"Twitter\"]\n",
    "db_reddit  = client[\"reddit\"]\n",
    "\n",
    "collections_twitter = db_twitter.collection_names()\n",
    "collections_reddit = db_reddit.collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter-temp: 0\n",
      "twitter-australia: 312,347\n",
      "twitter-other: 170,516,309\n",
      "reddit: 1,369,789\n",
      "family-violence-unique-2019-01-11: 259\n",
      "reddit-2019-02: 319,715\n",
      "family-violence-2019-01-11: 1,927,047\n",
      "reddit_temp: 0\n"
     ]
    }
   ],
   "source": [
    "for i in collections_twitter:\n",
    "    print(i+\": {:,}\".format(db_twitter[i].find({}).count()))\n",
    "    \n",
    "for i in collections_reddit:\n",
    "    print(i+\": {:,}\".format(db_reddit[i].find({}).count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Twitter\n",
    "## Compute number of posts based on creation date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct pipline for aggregation\n",
    "# Group by date, converted from timestamp\n",
    "\n",
    "pipeline = [\n",
    "    { \"$group\": {\n",
    "        \"_id\": {\n",
    "            \"$dateToString\": {\n",
    "                \"format\": \"%Y-%m-%d\",\n",
    "                \"date\": {\n",
    "                    \"$toDate\": { \"$toLong\": \"$timestamp_ms\" }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "        \"count\": { \"$sum\": 1 }\n",
    "        }\n",
    "    },\n",
    "    { \"$sort\": {\"_id\": 1}} #sort by date ascending\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Australia data\n",
    "\n",
    "aus_data = list(db_twitter['twitter-australia'].aggregate(pipeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet counts - Australia:\n",
      "\n",
      "\n",
      "Total: 0\n"
     ]
    }
   ],
   "source": [
    "# Print totals\n",
    "\n",
    "total = 0\n",
    "print('Tweet counts - Australia:\\n')\n",
    "for data in aus_data:\n",
    "    if data['_id']:\n",
    "        print(data['_id']+':', data['count'])\n",
    "        total += data['count']\n",
    "        \n",
    "print('\\nTotal:', total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_data = list(db_twitter['twitter-other'].aggregate(pipeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet counts - other countries:\n",
      "\n",
      "2019-01-04: 189\n",
      "2019-01-09: 43440\n",
      "\n",
      "Total: 43629\n"
     ]
    }
   ],
   "source": [
    "print('Tweet counts - other countries:\\n')\n",
    "total = 0\n",
    "for data in other_data:\n",
    "    if data['_id']:\n",
    "        print(data['_id']+':', data['count'])\n",
    "        total += data['count']\n",
    "\n",
    "print('\\nTotal:', total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter-daily-collection.csv is ready.\n"
     ]
    }
   ],
   "source": [
    "# Write results to file as csv\n",
    "\n",
    "file_name = 'output/twitter-daily-collection.csv'\n",
    "with open(file_name, 'w') as f:\n",
    "    # header\n",
    "    f.write('Date,Tweets from Australia,Tweets from Other Countries\\n')\n",
    "    \n",
    "    # iterate each day (other data much larger than aus data)\n",
    "    for data in other_data:\n",
    "        if data['_id']:\n",
    "            date = data['_id']\n",
    "            \n",
    "            # construct one csv line\n",
    "            line = date + ','\n",
    "            \n",
    "            # find if this date also has data in aus_data\n",
    "            aus_count = 0\n",
    "            for _data in aus_data:\n",
    "                if _data['_id'] == date:\n",
    "                    aus_count = _data['count']\n",
    "                    break\n",
    "            line += str(aus_count) + ',' + str(data['count']) + '\\n'\n",
    "            f.write(line)\n",
    "    \n",
    "print (file_name, 'is ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
