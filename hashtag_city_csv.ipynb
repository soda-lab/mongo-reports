{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import csv\n",
    "import pandas\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "import configparser \n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "ip = config['DEFAULT']['IP']\n",
    "port = config['DEFAULT']['MongoDB-Port']\n",
    "\n",
    "from pymongo import MongoClient\n",
    "client = MongoClient(ip, int(port))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_twitter = client[\"Twitter\"]\n",
    "collections_twitter = db_twitter.collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current year : 2019\n",
      "current week : 14\n"
     ]
    }
   ],
   "source": [
    "# get current year\n",
    "current_timestamp = int(time.time() * 1000)\n",
    "current_year = int(datetime.datetime.now().year)\n",
    "print(\"current year : \" + str(current_year))\n",
    "\n",
    "# get current week\n",
    "current_week = int((current_timestamp - 1546214400000)/1000/604800)+1\n",
    "print(\"current week : \" + str(current_week))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018_W51_Twitter_Australia: 20471\n",
      "2018_W51_Twitter_Other: 8978243\n",
      "2018_W52_Twitter_Australia: 38065\n",
      "2018_W52_Twitter_Other: 16940708\n",
      "2019_W01_Twitter_Australia: 40880\n",
      "2019_W01_Twitter_Other: 16994959\n",
      "2019_W02_Twitter_Australia: 37645\n",
      "2019_W02_Twitter_Other: 14474627\n",
      "2019_W03_Twitter_Australia: 52348\n",
      "2019_W03_Twitter_Other: 20416992\n",
      "2019_W04_Twitter_Australia: 59625\n",
      "2019_W04_Twitter_Other: 23417927\n",
      "2019_W05_Twitter_Australia: 61617\n",
      "2019_W05_Twitter_Other: 23917345\n",
      "2019_W06_Twitter_Australia: 61435\n",
      "2019_W06_Twitter_Other: 24176122\n",
      "2019_W07_Twitter_Australia: 28017\n",
      "2019_W07_Twitter_Other: 10484648\n",
      "2019_W08_Twitter_Australia: 60035\n",
      "2019_W08_Twitter_Other: 23446630\n",
      "2019_W09_Twitter_Australia: 58316\n",
      "2019_W09_Twitter_Other: 22293795\n",
      "2019_W10_Twitter_Australia: 40767\n",
      "2019_W10_Twitter_Other: 15941350\n",
      "2019_W11_Twitter_Australia: 68593\n",
      "2019_W11_Twitter_Other: 25345811\n",
      "2019_W12_Twitter_Australia: 50447\n",
      "2019_W12_Twitter_Other: 18090490\n",
      "2019_W13_Twitter_Australia: 62926\n",
      "2019_W13_Twitter_Other: 24379236\n"
     ]
    }
   ],
   "source": [
    "dic_collection = {}\n",
    "for i in collections_twitter:\n",
    "    if i.startswith(\"20\"):\n",
    "        year = i[0:4]\n",
    "        week = re.search('_(.+?)_', i).group(1)[1:]\n",
    "        if int(year) < current_year:\n",
    "            dic_collection[i] = \"{:}\".format(db_twitter[i].find({}).count())\n",
    "        else:\n",
    "            try:\n",
    "                if int(week) < current_week:\n",
    "                    dic_collection[i] = \"{:}\".format(db_twitter[i].find({}).count())\n",
    "            except: pass\n",
    "\n",
    "for key in sorted(dic_collection):\n",
    "    print(\"%s: %s\" % (key, dic_collection[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract a hashtag_city report from individual collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read city, state, country from csv file\n",
    "colnames = ['city', 'state', 'country']\n",
    "au_data = pandas.read_csv('supporting-files/au.csv', names=colnames, encoding=\"ISO-8859-1\")\n",
    "world_data = pandas.read_csv('supporting-files/world-cities.csv', names=colnames, encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [\n",
    "    {\"$match\": { \"entities.hashtags\": {\"$exists\":True,\"$ne\":[]}}},\n",
    "    {\"$match\": { \"lang\" : \"en\"}},\n",
    "    { \"$group\": {\n",
    "        \"_id\": {\n",
    "            \"hashtags\": \"$entities.hashtags\",\n",
    "            \"location\": \"$user.location\"},\n",
    "        \"count\": { \"$sum\": 1 },\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list from csv file\n",
    "def get_list_from_csv(data):\n",
    "    ci = data.city.tolist()\n",
    "    city = ci[1:]\n",
    "    st = data.state.tolist()\n",
    "    state = st[1:]\n",
    "    co = data.country.tolist()\n",
    "    country = co[1:]\n",
    "    return city,state,country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create foler if not exist\n",
    "def create_folder():\n",
    "    folder = \"output/hashtag_city/\"\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    return folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete existed collection from the list dic_collection\n",
    "def delete_collection(folder,dic_collection):\n",
    "    for input_file in glob.glob(os.path.join(folder,'*.csv')):\n",
    "        collection_name = re.search('{(.+?)}', input_file).group(1)\n",
    "        print(\"Existed collection: \" + collection_name)\n",
    "        del dic_collection[collection_name]\n",
    "    return dic_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to add count number\n",
    "def count(dc,data,exist,c):\n",
    "    dc += data[\"count\"]\n",
    "    exist = 1\n",
    "    c+=1\n",
    "    return dc,exist,c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append to dictionary\n",
    "def append_dic(data_format,exist,c,dic):\n",
    "    data_format.append(dic)\n",
    "    exist = 1\n",
    "    c+=1\n",
    "    return data_format,exist,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if exists then add count number\n",
    "def check_count(data_format, x,text,s_geo,exist,c,data):\n",
    "    for d in data_format:\n",
    "        s0 = d[\"id\"].split(\",\")[0]\n",
    "        s1 = s = d[\"id\"].split(\",\")[1]\n",
    "        if(x in d[\"id\"]) and (text in d[\"hashtag\"]) and (s_geo == \"city\"):\n",
    "            d[\"count\"],exist,c = count(d[\"count\"],data,exist,c)\n",
    "            break\n",
    "        elif (s0 == \"null\") and (x in d[\"id\"]) and (text in d[\"hashtag\"]) and (s_geo == \"state\"):\n",
    "            d[\"count\"],exist,c = count(d[\"count\"],data,exist,c)\n",
    "            break\n",
    "        elif (s1 == \"null\") and (x in d[\"id\"]) and (text in d[\"hashtag\"])and (s_geo == \"country\"):\n",
    "            d[\"count\"],exist,c = count(d[\"count\"],data,exist,c)\n",
    "            break\n",
    "    return data_format,exist,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate running time\n",
    "def calculate_time(start_time, t):\n",
    "    current_time = time.time()\n",
    "    duration = current_time - start_time\n",
    "    if (duration/3600) >= (t+1):\n",
    "        t += 1\n",
    "        print(\"The program is still running, already run for about \"+ str(t) + \" hours.\")\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method for each loop\n",
    "def floop(s_geo,geo,data,data_format,text,state,country,exist,c,start_time,t):\n",
    "    for x in geo: \n",
    "        if isinstance(x,str):\n",
    "            if s_geo == \"city\":\n",
    "                loc = data[\"_id\"][\"location\"].lower().replace(\"australia\",\"\")\n",
    "            else:\n",
    "                loc = data[\"_id\"][\"location\"].lower()\n",
    "            if x.lower() in loc:\n",
    "                index = geo.index(x)\n",
    "    \n",
    "                if s_geo == \"city\":\n",
    "                    sid = x + ',' + str(state[index]) + \",\" + str(country[index])\n",
    "                if s_geo == \"state\":\n",
    "                    sid = \"null\" + \",\" + x + \",\" + str(country[index])\n",
    "                if s_geo == \"country\":\n",
    "                    sid = \"null\" + \",\" + \"null\" + ',' + x\n",
    "                dic = {\"id\":sid,\"hashtag\":text,\"count\":data[\"count\"]}\n",
    "                \n",
    "                if len(data_format)>0:\n",
    "                    data_format,exist,c = check_count(data_format, x,text,s_geo,exist,c,data)\n",
    "                    if exist == 0:\n",
    "                        data_format,exist,c = append_dic(data_format,exist,c,dic)\n",
    "                else: \n",
    "                    data_format,exist,c = append_dic(data_format,exist,c,dic)\n",
    "                    \n",
    "                #print(\"No.\" + str(c) + s_geo + \": \" + x)\n",
    "                \n",
    "                # print every hour if it's still running\n",
    "                t = calculate_time(start_time, t)\n",
    "                break\n",
    "   \n",
    "    return data_format,exist,c,t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write csv file\n",
    "def write_csv(collection,total_tweet,tweets_htag,data_format):\n",
    "    \n",
    "    file_name = \"output/hashtag_city/{\" + collection + \"}_hashtag_city.csv\"\n",
    "    with open(file_name, 'w') as f:\n",
    "        # header\n",
    "        f.write('hashtag,city,state,country,number of tweets,tweets_htag,tweets_nohtag\\n')\n",
    "            \n",
    "        tweets_nohtag = int(total_tweet)-tweets_htag\n",
    "\n",
    "        for data in data_format:\n",
    "            city = data['id'].split(\",\")[0]\n",
    "            state = data['id'].split(\",\")[1]\n",
    "            country = data['id'].split(\",\")[2]\n",
    "            if \"Australia\" in collection:\n",
    "                if state == 'Victoria':\n",
    "                    state = 'VIC'\n",
    "\n",
    "            line = data[\"hashtag\"] + ',' + city + ',' + state + ',' +  country + ',' + \\\n",
    "            str(data['count']) + ','+ str(tweets_htag)+ ',' +str(tweets_nohtag)+ '\\n'\n",
    "            \n",
    "            f.write(line)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_columns = ['hashtag','city','state','country','count']\n",
    "\n",
    "#create folder if not exist\n",
    "folder = create_folder()\n",
    "    \n",
    "# delete existed collection from the list dic_collection\n",
    "dic_collection = delete_collection(folder,dic_collection)\n",
    "       \n",
    "for collection in sorted(dic_collection):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    t = 0\n",
    " \n",
    "    total_tweet = dic_collection[collection]\n",
    "    if \"Australia\" in collection:     \n",
    "        city, state, country = get_list_from_csv(au_data)\n",
    "    elif \"Other\" in collection:\n",
    "        city, state, country = get_list_from_csv(world_data)\n",
    "\n",
    "    print(\"-----------------------\\n\")\n",
    "    print(\"Processing on collection: \" + collection)\n",
    "\n",
    "    data_format = []\n",
    "    \n",
    "    print(\"Aggregating...\")\n",
    "    data_list = list(db_twitter[collection].aggregate(pipeline,allowDiskUse=True))\n",
    "    print(\"Aggragation finished.\")\n",
    "    c = 0 \n",
    "    tweets_htag = 0\n",
    "    \n",
    "    if len(data_list) > 0 : \n",
    "        for data in data_list:\n",
    "            tweets_htag += data[\"count\"]\n",
    "            for htag in data[\"_id\"][\"hashtags\"]:\n",
    "                # get hashtag\n",
    "                text = htag[\"text\"].lower()\n",
    "                # check if it is in English\n",
    "                if(re.match(\"^[a-zA-Z0-9]*$\",text)):\n",
    "                    exist = 0\n",
    "                    # check if the location is null\n",
    "                    if data[\"_id\"][\"location\"] is not None: \n",
    "                        s_geo = \"city\"\n",
    "                        data_format,exist,c,t = floop(s_geo,city,data,data_format,text,state,country,exist,c,start_time,t)\n",
    "                        if exist == 0:\n",
    "                            s_geo = \"state\"\n",
    "                            data_format,exist,c,t = floop(s_geo,state,data,data_format,text,state,country,exist,c,start_time,t)\n",
    "                        if exist == 0:\n",
    "                            s_geo = \"country\"\n",
    "                            data_format,exist,c,t = floop(s_geo,country,data,data_format,text,state,country,exist,c,start_time,t)\n",
    "\n",
    "\n",
    "        print(\"hashtag list is finished\")\n",
    "\n",
    "        write_csv(collection,total_tweet,tweets_htag,data_format)\n",
    "\n",
    "        print (\"csv file for collection \" + collection + ' is finished.')\n",
    "        print(\"-----------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
